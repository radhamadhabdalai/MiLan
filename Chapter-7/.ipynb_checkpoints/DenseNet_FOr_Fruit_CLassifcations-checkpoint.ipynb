{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0c59a02-1fc6-459b-a864-3c44da046df5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################################################################################\n",
    "    #Copyright (c) 2023, 2024 , Prof. Radhamadhab Dalai, ITER , Siksha O Aanusandhan University\n",
    "    #Odisha, India,\n",
    "    #Author's email address :  radhamadhabdalai@soa.ac.in\n",
    " ########################################################################################################\n",
    "\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "import seaborn as sns\n",
    "import os\n",
    "print(os.listdir(\"Datasets/darknet/\"))\n",
    "\n",
    "# Any results you write to the current directory are saved as output.\n",
    "\n",
    "\n",
    "df=pd.read_csv(\"Datasets/darknet/train.csv\")\n",
    "df.head()\n",
    "\n",
    "\n",
    "print(\"Number of samples: \",len(df))\n",
    "print(\"Number of Labels: \",np.unique(df.has_cactus))\n",
    "\n",
    "sns.distplot(df.has_cactus)\n",
    "\n",
    "\n",
    "from PIL import Image \n",
    "from skimage.transform import resize\n",
    "train=pd.read_csv(\"Datasets/darknet/train.csv\")\n",
    "train_images=[]\n",
    "path=\"Datasets/darknet/train/train/\"\n",
    "for i in train.id:\n",
    "    image=plt.imread(path+i)\n",
    "    train_images.append(image)\n",
    "\n",
    "\n",
    "train_images=np.asarray(train_images)\n",
    "X=train_images\n",
    "y=train.has_cactus\n",
    "print(\"Labels: \",y.shape)\n",
    "print(\"images: \",X.shape)\n",
    "\n",
    "\n",
    "plt.imshow(X[2])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2b7808d-1ffe-4cfa-9eef-7b241891a16a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Model\n",
    "from keras.layers import Conv2D, MaxPooling2D, Dense, Input, Activation, Dropout, GlobalAveragePooling2D, \\\n",
    "    BatchNormalization, concatenate, AveragePooling2D\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "\n",
    "\n",
    "def conv_layer(conv_x, filters):\n",
    "    conv_x = BatchNormalization()(conv_x)\n",
    "    conv_x = Activation('relu')(conv_x)\n",
    "    conv_x = Conv2D(filters, (3, 3), kernel_initializer='he_uniform', padding='same', use_bias=False)(conv_x)\n",
    "    conv_x = Dropout(0.2)(conv_x)\n",
    "\n",
    "    return conv_x\n",
    "\n",
    "\n",
    "def dense_block(block_x, filters, growth_rate, layers_in_block):\n",
    "    for i in range(layers_in_block):\n",
    "        each_layer = conv_layer(block_x, growth_rate)\n",
    "        block_x = concatenate([block_x, each_layer], axis=-1)\n",
    "        filters += growth_rate\n",
    "\n",
    "    return block_x, filters\n",
    "\n",
    "\n",
    "def transition_block(trans_x, tran_filters):\n",
    "    trans_x = BatchNormalization()(trans_x)\n",
    "    trans_x = Activation('relu')(trans_x)\n",
    "    trans_x = Conv2D(tran_filters, (1, 1), kernel_initializer='he_uniform', padding='same', use_bias=False)(trans_x)\n",
    "    trans_x = AveragePooling2D((2, 2), strides=(2, 2))(trans_x)\n",
    "\n",
    "    return trans_x, tran_filters\n",
    "\n",
    "\n",
    "def dense_net(filters, growth_rate, classes, dense_block_size, layers_in_block):\n",
    "    input_img = Input(shape=(32, 32, 3))\n",
    "    x = Conv2D(24, (3, 3), kernel_initializer='he_uniform', padding='same', use_bias=False)(input_img)\n",
    "\n",
    "    dense_x = BatchNormalization()(x)\n",
    "    dense_x = Activation('relu')(x)\n",
    "\n",
    "    dense_x = MaxPooling2D((3, 3), strides=(2, 2), padding='same')(dense_x)\n",
    "    for block in range(dense_block_size - 1):\n",
    "        dense_x, filters = dense_block(dense_x, filters, growth_rate, layers_in_block)\n",
    "        dense_x, filters = transition_block(dense_x, filters)\n",
    "\n",
    "    dense_x, filters = dense_block(dense_x, filters, growth_rate, layers_in_block)\n",
    "    dense_x = BatchNormalization()(dense_x)\n",
    "    dense_x = Activation('relu')(dense_x)\n",
    "    dense_x = GlobalAveragePooling2D()(dense_x)\n",
    "\n",
    "    output = Dense(classes, activation='softmax')(dense_x)\n",
    "\n",
    "    return Model(input_img, output)\n",
    "\n",
    "from keras.utils import np_utils\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33)\n",
    "Cat_test_y = np_utils.to_categorical(y_test)\n",
    "y_train=np_utils.to_categorical(y_train)\n",
    "\n",
    "print(\"X_train shape : \",X_train.shape)\n",
    "print(\"y_train shape : \",y_train.shape)\n",
    "print(\"X_test shape : \",X_test.shape)\n",
    "print(\"y_test shape : \",y_test.shape)\n",
    "\n",
    "\n",
    "\n",
    "dense_block_size = 3\n",
    "layers_in_block = 4\n",
    "\n",
    "growth_rate = 12\n",
    "classes = 2\n",
    "model = dense_net(growth_rate * 2, growth_rate, classes, dense_block_size, layers_in_block)\n",
    "model.summary()\n",
    "\n",
    "\n",
    "# training\n",
    "batch_size = 32\n",
    "epochs = 10\n",
    "optimizer = Adam(lr=0.0001, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n",
    "model.compile(optimizer = optimizer, loss = 'binary_crossentropy', metrics=['accuracy'])\n",
    "history=model.fit(X_train,y_train, epochs=epochs, batch_size=batch_size, shuffle=True,validation_data=(X_test, Cat_test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b9ac507-7c81-418a-a676-531d31791af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the training loss and accuracy\n",
    "import sys\n",
    "import matplotlib\n",
    "print(\"Generating plots...\")\n",
    "sys.stdout.flush()\n",
    "matplotlib.use(\"Agg\")\n",
    "matplotlib.pyplot.style.use(\"ggplot\")\n",
    "matplotlib.pyplot.figure()\n",
    "N = epochs \n",
    "matplotlib.pyplot.plot(np.arange(0, N), history.history[\"loss\"], label=\"train_loss\")\n",
    "matplotlib.pyplot.plot(np.arange(0, N), history.history[\"val_loss\"], label=\"val_loss\")\n",
    "matplotlib.pyplot.plot(np.arange(0, N), history.history[\"acc\"], label=\"train_acc\")\n",
    "matplotlib.pyplot.plot(np.arange(0, N), history.history[\"val_acc\"], label=\"val_acc\")\n",
    "matplotlib.pyplot.title(\"Cactus Image Classification\")\n",
    "matplotlib.pyplot.xlabel(\"Epoch #\")\n",
    "matplotlib.pyplot.ylabel(\"Loss/Accuracy\")\n",
    "matplotlib.pyplot.legend(loc=\"lower left\")\n",
    "matplotlib.pyplot.savefig(\"plot.png\")\n",
    "\n",
    "\n",
    "from sklearn import metrics\n",
    "label_pred = model.predict(X_test)\n",
    "\n",
    "pred = []\n",
    "for i in range(len(label_pred)):\n",
    "    pred.append(np.argmax(label_pred[i]))\n",
    "\n",
    "Y_test = np.argmax(Cat_test_y, axis=1) # Convert one-hot to index\n",
    "\n",
    "print(metrics.classification_report(Y_test, pred))\n",
    "\n",
    "\n",
    "from sklearn import metrics\n",
    "label_pred = model.predict(X_test)\n",
    "\n",
    "pred = []\n",
    "for i in range(len(label_pred)):\n",
    "    pred.append(np.argmax(label_pred[i]))\n",
    "\n",
    "Y_test = np.argmax(Cat_test_y, axis=1) # Convert one-hot to index\n",
    "\n",
    "print(metrics.accuracy_score(Y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f28bb820-9892-4b8e-972f-d139bbd8eddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#training all data on this model\n",
    "model = dense_net(growth_rate * 2, growth_rate, classes, dense_block_size, layers_in_block)\n",
    "batch_size = 32\n",
    "epochs = 20\n",
    "optimizer = Adam(lr=0.0001, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n",
    "model.compile(optimizer = optimizer, loss = 'binary_crossentropy', metrics=['accuracy'])\n",
    "y= np_utils.to_categorical(y)\n",
    "history=model.fit(X,y, epochs=epochs, batch_size=batch_size, shuffle=True,verbose=0)\n",
    "\n",
    "from PIL import Image \n",
    "from skimage.transform import resize\n",
    "sample=pd.read_csv(\"Datasets/darknet/sample_submission.csv\")\n",
    "test_images=[]\n",
    "path=\"Datasets/darknet/test/test/\"\n",
    "for i in sample.id:\n",
    "    image=plt.imread(path+i)\n",
    "    test_images.append(image)\n",
    "\n",
    "\n",
    "# prediction\n",
    "test_images=np.asarray(test_images)\n",
    "test_images=test_images.reshape(test_images.shape[0],32,32,3)\n",
    "pred1=model.predict(test_images)\n",
    "pred = []\n",
    "for i in range(len(test_images)):\n",
    "    pred.append(np.argmax(pred1[i]))\n",
    "\n",
    "\n",
    "results = pd.DataFrame({\"id\" : sample.id, \"has_cactus\": pred})\n",
    "results.to_csv(\"submission.csv\", index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
