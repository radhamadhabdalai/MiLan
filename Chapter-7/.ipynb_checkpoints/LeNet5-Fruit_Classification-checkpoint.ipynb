{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14c98a8e-7c8b-4915-bf3d-fb6bc60eee16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading complete!\n",
      "Training set size : 17206\n",
      "Testing set size : 5756\n",
      "Number of classes / fruits: 34\n",
      "Original labels[ 2 12  6  8 15 28 12 25  3  5]\n",
      "Size of x_valid: (5756,)\n",
      "Size of y_valid: (5756, 34)\n",
      "Size of x_test: (0,)\n",
      "Size of y_test: (0, 34)\n",
      "Training set shape: (17206, 100, 100, 3)\n",
      "Validation set shap: (5756, 100, 100, 3)\n",
      "Test set shape: (0,)\n",
      "Training image shape: (100, 100, 3)\n"
     ]
    }
   ],
   "source": [
    "#############################################################################################################\n",
    "    #Copyright (c) 2023, 2024 , Prof. Radhamadhab Dalai, ITER , Siksha O Aanusandhan University\n",
    "    #Odisha, India,\n",
    "    #Author's email address :  radhamadhabdalai@soa.ac.in\n",
    " ########################################################################################################\n",
    "\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from sklearn.datasets import load_files\n",
    "import numpy as np\n",
    "# from keras.utils import np_utils\n",
    "\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Data specifications\n",
    "# This script should be in the overarching directory of the fruit360 dataset. \n",
    "\n",
    "train_dir = \"fruits-360/Training\"\n",
    "test_dir = \"fruits-360/Test\"\n",
    "\n",
    "\n",
    "def load_dataset(path):\n",
    "    data = load_files(path)\n",
    "    files = np.array(data[\"filenames\"])\n",
    "    targets = np.array(data[\"target\"])\n",
    "    target_labels = np.array(data[\"target_names\"])\n",
    "    return files,targets,target_labels\n",
    "    \n",
    "\n",
    "# Load data \n",
    "\n",
    "x_train, y_train,target_labels = load_dataset(train_dir)\n",
    "x_test, y_test,_ = load_dataset(test_dir)\n",
    "print(\"Loading complete!\")\n",
    "\n",
    "print(\"Training set size : \" + str(x_train.shape[0]))\n",
    "print(\"Testing set size : \" + str(x_test.shape[0]))\n",
    "\n",
    "# Let's confirm the number of classes\n",
    "\n",
    "no_of_classes = len(np.unique(y_train))\n",
    "print(\"Number of classes / fruits: \" + str(no_of_classes))\n",
    "\n",
    "# The target labels are originally numbers corresponding to class labels\n",
    "\n",
    "print(\"Original labels\" + str(y_train[0:10]))\n",
    "\n",
    "# Make one-hot\n",
    "\n",
    "y_train = to_categorical(y_train, num_classes=no_of_classes)\n",
    "y_test = to_categorical(y_test, num_classes=no_of_classes)\n",
    "\n",
    "\n",
    "# y_train = np_utils.to_categorical(y_train,no_of_classes)\n",
    "# y_test = np_utils.to_categorical(y_test,no_of_classes)\n",
    "y_train[0] \n",
    "\n",
    "# Divide the test samples into validation and test samples\n",
    "\n",
    "x_test,x_valid = x_test[6969:],x_test[:6969]\n",
    "y_test,y_valid = y_test[6969:],y_test[:6969]\n",
    "print(\"Size of x_valid: \" + str(x_valid.shape))\n",
    "print(\"Size of y_valid: \" + str(y_valid.shape))\n",
    "print(\"Size of x_test: \" + str(x_test.shape))\n",
    "print(\"Size of y_test: \" + str(y_test.shape))\n",
    "\n",
    "# Convert Images to np arrays\n",
    "\n",
    "def convert_image_to_array(files):\n",
    "    images_as_array=[]\n",
    "    for file in files:\n",
    "        # Convert to Numpy Array\n",
    "        images_as_array.append(tf.keras.preprocessing.image.img_to_array(tf.keras.preprocessing.image.load_img(file)))\n",
    "    return images_as_array\n",
    "\n",
    "x_train = np.array(convert_image_to_array(x_train))\n",
    "print(\"Training set shape: \" + str(x_train.shape))\n",
    "\n",
    "x_valid = np.array(convert_image_to_array(x_valid))\n",
    "print(\"Validation set shap: \" + str(x_valid.shape))\n",
    "\n",
    "x_test = np.array(convert_image_to_array(x_test))\n",
    "print(\"Test set shape: \" + str(x_test.shape))\n",
    "\n",
    "print(\"Training image shape: \" + str(x_train[0].shape))\n",
    "\n",
    "# Convert pixel values to 0->1 \n",
    "\n",
    "x_train = x_train.astype('float32')/255\n",
    "x_valid = x_valid.astype('float32')/255\n",
    "x_test = x_test.astype('float32')/255\n",
    "\n",
    "# Plot images\n",
    "\n",
    "fig = plt.figure(figsize =(28,6))\n",
    "for i in range(12):\n",
    "    ax = fig.add_subplot(3,4,i+1,xticks=[],yticks=[])\n",
    "    ax.imshow(np.squeeze(x_train[i]))\n",
    "\n",
    "plt.savefig(\"fruits.png\")\n",
    "plt.show()\n",
    "print(\"Done plotting\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "064f7473-bd69-4daa-8c97-60f396b75f26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the CNN\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D,MaxPooling2D\n",
    "from keras.layers import Activation, Dense, Flatten, Dropout, BatchNormalization\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras import backend as K\n",
    "import tensorflow as tf \n",
    "\n",
    "\n",
    "#Lenet-5 model\n",
    "# model = keras.Sequential()\n",
    "\n",
    "# model.add(layers.Conv2D(filters=6, kernel_size=(3, 3), activation='relu', input_shape=(32,32,1)))\n",
    "# model.add(layers.AveragePooling2D())\n",
    "\n",
    "# model.add(layers.Conv2D(filters=16, kernel_size=(3, 3), activation='relu'))\n",
    "# model.add(layers.AveragePooling2D())\n",
    "\n",
    "# model.add(layers.Flatten())\n",
    "\n",
    "# model.add(layers.Dense(units=120, activation='relu'))\n",
    "\n",
    "# model.add(layers.Dense(units=84, activation='relu'))\n",
    "\n",
    "# model.add(layers.Dense(units=10, activation = 'softmax'))\n",
    "\n",
    "\n",
    "\n",
    "# Add 3 convolutional layers and then two fully connected ones\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(filters=32, kernel_size = (4,4), input_shape = (100, 100, 3), activation=\"relu\", strides=2, padding=\"valid\"))\n",
    "model.add(MaxPooling2D(pool_size=(3, 3)))\n",
    "\n",
    "model.add(Conv2D(filters=64, kernel_size=2, padding=\"valid\", activation=\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "\n",
    "model.add(Conv2D(filters=64, kernel_size=2, padding=\"valid\", activation=\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "\n",
    "# Move to fully connected layers\n",
    "\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(270, use_bias=True))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(200, use_bias=True))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(131, activation='softmax'))\n",
    "print(model.summary())\n",
    "\n",
    "# Use Adam optimization\n",
    "\n",
    "model.compile(loss=tf.keras.losses.CategoricalCrossentropy() , optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3), metrics=['accuracy'])\n",
    "print('Compiled!')\n",
    "\n",
    "# Metadata and model fit\n",
    "\n",
    "batch_size = 32\n",
    "checkpointer = ModelCheckpoint(filepath = 'cnn_fruits.hdf5', verbose = 1, save_best_only = True)\n",
    "history = model.fit(x_train,y_train, batch_size = 32, epochs=5, validation_data=(x_valid, y_valid), callbacks = [checkpointer], verbose=2, shuffle=True)\n",
    "\n",
    "# Load the weights that yielded the best validation accuracy\n",
    "\n",
    "model.load_weights('cnn_fruits.hdf5')\n",
    "\n",
    "# Evaluate and print test accuracy\n",
    "\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('\\n', 'Test accuracy:', score[1])\n",
    "\n",
    "# Visualize test prediction.\n",
    "\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "# Plot a random sample of test images, the model's predicted labels, and ground truth\n",
    "\n",
    "fig = plt.figure(figsize=(16, 9))\n",
    "\n",
    "for i, idx in enumerate(np.random.choice(x_test.shape[0], size=16, replace=False)):\n",
    "    ax = fig.add_subplot(4, 4, i + 1, xticks=[], yticks=[])\n",
    "    ax.imshow(np.squeeze(x_test[idx]))\n",
    "    pred_idx = np.argmax(y_pred[idx])\n",
    "    true_idx = np.argmax(y_test[idx])\n",
    "    ax.set_title(\"{} ({})\".format(target_labels[pred_idx], target_labels[true_idx]),\n",
    "                 color=(\"green\" if pred_idx == true_idx else \"red\"))\n",
    "\n",
    "plt.savefig(\"fruits_model.png\")\n",
    "plt.show()\n",
    "plt.figure(1)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a05cdf29-c362-40bb-9216-e1dde208c05b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
