{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4d1fa1eb-18f9-48db-b004-13770bff1717",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-17 10:20:12.376591: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-05-17 10:20:12.441019: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-05-17 10:20:13.043801: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-05-17 10:20:13.046622: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-05-17 10:20:15.893341: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 17206 images belonging to 34 classes.\n",
      "Found 5756 images belonging to 34 classes.\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_v3/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "87910968/87910968 [==============================] - 8s 0us/step\n"
     ]
    }
   ],
   "source": [
    "######################################################################################\n",
    "Copyright (c) 2023, 2024 , Prof. Radhamadhab Dalai, ITER , Siksha O Aanusandhan University, \n",
    "Odisha, India\n",
    "Author's email address :  radhamadhabdalai@soa.ac.in\n",
    "################################################################################### \n",
    "#read in libraries\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend, models, layers, optimizers\n",
    "import numpy as np\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from IPython.display import display\n",
    "from PIL import Image\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import os, shutil\n",
    "from tensorflow.keras.models import Model\n",
    "np.random.seed(42)\n",
    "\n",
    "# Specify the base directory where images are located.\n",
    "base_dir = 'fruits-360/'\n",
    "\n",
    "\n",
    "# Specify the traning, validation, and test dirrectories.  \n",
    "train_dir = os.path.join(base_dir, 'Training')\n",
    "test_dir = os.path.join(base_dir, 'Test')\n",
    "\n",
    "# Normalize the pixels in the train data images, resize and augment the data.\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,# The image augmentaion function in Keras\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2, # Zoom in on image by 20%\n",
    "    horizontal_flip=True) # Flip image horizontally \n",
    "\n",
    "# Normalize the test data imagees, resize them but don't augment them\n",
    "test_datagen = ImageDataGenerator(rescale=1./255) \n",
    "\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(299, 299),\n",
    "    batch_size=16,\n",
    "    class_mode='categorical')\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(299, 299),\n",
    "    batch_size=16,\n",
    "    class_mode='categorical')\n",
    "\n",
    "# Load InceptionV3 library\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "\n",
    "# Always clear the backend before training a model\n",
    "backend.clear_session()\n",
    "\n",
    "# InceptionV3 model and use the weights from imagenet\n",
    "conv_base = InceptionV3(weights = 'imagenet', #Useing the inception_v3 CNN that was trained on ImageNet data.  \n",
    "                  include_top = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2141f52-9ea6-49c6-bb56-a564bd194a03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model to work.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 7013066463502284955\n",
      "xla_global_id: -1\n",
      "]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_19372/4150957506.py:30: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  history = model_InceptionV3.fit_generator(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "  81/1076 [=>............................] - ETA: 2:21:36 - loss: 1.7025 - accuracy: 0.5285"
     ]
    }
   ],
   "source": [
    "# Connect the InceptionV3 output to the fully connected layers\n",
    "InceptionV3_model = conv_base.output\n",
    "pool = GlobalAveragePooling2D()(InceptionV3_model)\n",
    "dense_1 = layers.Dense(512, activation = 'relu')(pool)\n",
    "output = layers.Dense(34, activation = 'softmax')(dense_1)\n",
    "\n",
    "# Create an example of the Archictecture to plot on a graph\n",
    "model_example = models.Model(inputs=conv_base.input, outputs=output)\n",
    "# plot graph\n",
    "plot_model(model_example)\n",
    "\n",
    "\n",
    "# Define/Create the model for training\n",
    "model_InceptionV3 = models.Model(inputs=conv_base.input, outputs=output)\n",
    "\n",
    "# Compile the model with categorical crossentropy for the loss function and SGD for the optimizer with the learning\n",
    "# rate at 1e-4 and momentum at 0.9\n",
    "model_InceptionV3.compile(loss='categorical_crossentropy',\n",
    "              optimizer=optimizers.SGD(lr=1e-4, momentum=0.9),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "# Import from tensorflow the module to read the GPU device and then print\n",
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())\n",
    "\n",
    "# Execute the model with fit_generator within the while loop utilizing the discovered GPU\n",
    "import tensorflow as tf\n",
    "with tf.device(\"/device:GPU:0\"):\n",
    "    history = model_InceptionV3.fit_generator(\n",
    "        train_generator,\n",
    "        epochs=5,\n",
    "        validation_data=test_generator,\n",
    "        verbose = 1,\n",
    "        callbacks=[EarlyStopping(monitor='val_accuracy', patience = 5, restore_best_weights = True)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62ffdc6c-bc17-46bc-ba5d-8646c5388443",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary of the model history \n",
    "import matplotlib.pyplot as plt\n",
    "history_dict = history.history\n",
    "loss_values = history_dict['loss']\n",
    "val_loss_values = history_dict['val_loss']\n",
    "acc_values = history_dict['accuracy']\n",
    "val_acc_values = history_dict['val_accuracy']\n",
    "epochs = range(1, len(history_dict['accuracy']) + 1)\n",
    "\n",
    "# Plot the training/validation loss\n",
    "plt.plot(epochs, loss_values, 'bo', label = 'Training loss')\n",
    "plt.plot(epochs, val_loss_values, 'b', label = 'Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Plot the training/validation accuracy\n",
    "plt.plot(epochs, acc_values, 'bo', label = 'Training accuracy')\n",
    "plt.plot(epochs, val_acc_values, 'b', label = 'Validation accuracy')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Evaluate the test accuracy and test loss of the model\n",
    "test_loss, test_acc = model_InceptionV3.evaluate_generator(test_generator)\n",
    "\n",
    "print('Model testing accuracy/testing loss:', test_acc, \" \", test_loss)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
