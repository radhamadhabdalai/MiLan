{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22f01713-41f4-40b7-b9e3-42bdd1b18233",
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################################################################################\n",
    "    #Copyright (c) 2023, 2024 , Prof. Radhamadhab Dalai, ITER , Siksha O Aanusandhan University\n",
    "    #Odisha, India,\n",
    "    #Author's email address :  radhamadhabdalai@soa.ac.in\n",
    " ########################################################################################################\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
    "from tensorflow.keras.layers import AveragePooling2D, GlobalAveragePooling2D, MaxPooling2D,\\\n",
    "    ZeroPadding2D, Dense, multiply, Reshape, Conv2D, \\\n",
    "    Flatten, add, BatchNormalization, Activation, Input\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from keras.regularizers import l2\n",
    "from .utils import se_block\n",
    "\n",
    "__all__ = [\"SEResNet18\", \"SEResNet50\", \"SEResNet101\", \"SEResNet154\"]\n",
    "\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D,\\\n",
    "   Dense, multiply, Reshape\n",
    "from tensorflow.keras import backend as K\n",
    "   \n",
    "def se_block(in_block, ratio=16):\n",
    "  \"\"\"Creates channel-wise squeeze and excite block \n",
    "\n",
    "  args:\n",
    "    input_tensor: input keras tensor\n",
    "    ch: no. of channels in \n",
    "    ratio: no. of filters out\n",
    "\n",
    "  Returns: a Keras tensor \n",
    "\n",
    "  References:\n",
    "    -   [Squeeze and Excitation Networks](https://arxiv.org/abs/1709.01507)\n",
    "  \"\"\"\n",
    "  channel_axis = 1 if K.image_data_format() == \"channels_first\" else -1\n",
    "  filters = in_block.shape.as_list()[channel_axis]\n",
    "  x = GlobalAveragePooling2D()(in_block) # a vector of N dim. of in_block\n",
    "  x = Reshape((1, 1, filters))(x)\n",
    "  x = Dense(filters//ratio, activation=\"relu\")(x)\n",
    "  x = Dense(filters, activation=\"sigmoid\")(x)\n",
    "\n",
    "  return multiply([in_block, x])\n",
    "\n",
    "class SEResNet:\n",
    "    @staticmethod\n",
    "    def residual_module(in_block, K, stride, chanDim, red=False,\n",
    "                          reg= 1e-4, bnEps=2e-5, bnMom=.9):\n",
    "      \"\"\"Creates Pre-activation bottleneck residual module +\n",
    "        SE block\n",
    "\n",
    "        Arguments:\n",
    "          in_block: input keras tensor\n",
    "          K: no. of channels out\n",
    "          red: boolean flag for reduction in spatial feature map\n",
    "          reg: regulaizer param for conv.\n",
    "\n",
    "        Returns: a Keras tensor\n",
    "\n",
    "        References:\n",
    "          -   [ResNet](https://arxiv.org/abs/1512.03385)\n",
    "          -   [Squeeze-and-Excitation Networks ] (https://arxiv.org/abs/1709.01507)\n",
    "      \"\"\"\n",
    "\n",
    "      x = in_block\n",
    "      chan_in = in_block.shape.as_list()[-1]\n",
    "      bn1 = BatchNormalization(axis=chanDim, epsilon=bnEps, momentum=bnMom)(x)\n",
    "      relu1 = Activation(\"relu\")(bn1)\n",
    "      conv1 = Conv2D(filters=int(K * .25), kernel_size=(1, 1),\n",
    "                      use_bias=False,\n",
    "                      kernel_regularizer=l2(reg))(relu1) #Conv2D learns 1/4(0.25) of the last conv filter\n",
    "\n",
    "      bn2 = BatchNormalization(axis=chanDim, epsilon=bnEps, momentum=bnMom)(conv1)\n",
    "      relu2 = Activation(\"relu\")(bn2)\n",
    "      conv2 = Conv2D(filters=int(K * .25), kernel_size=(3, 3), strides=stride,\n",
    "                      padding=\"same\",\n",
    "                      use_bias=False,\n",
    "                      kernel_regularizer=l2(reg))(relu2) #Conv2D learns 1/4(0.25) of the last conv filter\n",
    "\n",
    "      bn3 = BatchNormalization(axis=chanDim, epsilon=bnEps, momentum=bnMom)(conv2)\n",
    "      relu3 = Activation(\"relu\")(bn3)\n",
    "      conv3 = Conv2D(filters=K, kernel_size=(1, 1),\n",
    "                      kernel_regularizer=l2(reg))(relu3)\n",
    "\n",
    "      if red:\n",
    "          x = Conv2D(filters=K, kernel_size=(1, 1), strides=stride,\n",
    "                      kernel_regularizer=l2(reg))(relu1)\n",
    "      x = se_block(x)\n",
    "      return add([x, conv3])\n",
    "\n",
    "    @staticmethod\n",
    "    def build(width, height, depth, classes, stages, filters, include_top, pooling,\n",
    "              reg=1e-3, bnEps=2e-5, bnMom=0.0):\n",
    "      \"\"\" Instantiate the Squeeze and Excite ResNet architecture. Note that ,\n",
    "          when using TensorFlow for best performance you should set\n",
    "          `image_data_format=\"channels_last\"` in your Keras config\n",
    "          at ~/.keras/keras.json.\n",
    "          The dimension ordering\n",
    "          convention used by the model is the one\n",
    "          specified in your Keras config file.\n",
    "          # Arguments\n",
    "              initial_conv_filters: number of features for the initial convolution\n",
    "              depth: number or layers in the each block, defined as a list.\n",
    "                  ResNet-50  = [3, 4, 6, 3]\n",
    "                  ResNet-101 = [3, 6, 23, 3]\n",
    "                  ResNet-152 = [3, 8, 36, 3]\n",
    "              filters: number of filters per block, defined as a list.\n",
    "                  filters = [64, 128, 256, 512\n",
    "              reg: weight decay (l2 norm)\n",
    "              include_top: whether to include the fully-connected\n",
    "                  layer at the top of the network.\n",
    "              input_shape: optional shape tuple, only to be specified\n",
    "                  if `include_top` is False (otherwise the input shape\n",
    "                  has to be `(224, 224, 3)` (with `tf` dim ordering)\n",
    "                  or `(3, 224, 224)` (with `th` dim ordering).\n",
    "                  It should have exactly 3 inputs channels,\n",
    "                  and width and height should be no smaller than 8.\n",
    "                  E.g. `(200, 200, 3)` would be one valid value.\n",
    "              pooling: Optional pooling mode for feature extraction\n",
    "                  when `include_top` is `False`.\n",
    "                  - `None` means that the output of the model will be\n",
    "                      the 4D tensor output of the\n",
    "                      last convolutional layer.\n",
    "                  - `avg` means that global average pooling\n",
    "                      will be applied to the output of the\n",
    "                      last convolutional layer, and thus\n",
    "                      the output of the model will be a 2D tensor.\n",
    "                  - `max` means that global max pooling will\n",
    "                      be applied.\n",
    "              classes: optional number of classes to classify images\n",
    "                  into, only to be specified if `include_top` is True, and\n",
    "                  if no `weights` argument is specified.\n",
    "\n",
    "          # Returns\n",
    "              A Keras model instance.\n",
    "      \"\"\"\n",
    "      inputShape = (height, width, depth)\n",
    "      chanDim = -1\n",
    "\n",
    "      if K.image_data_format() == \"channels_first\":\n",
    "        inputShape = (depth, height, width)\n",
    "        chanDim = 1\n",
    "\n",
    "      inputs = Input(shape=inputShape)\n",
    "\n",
    "\n",
    "      # block 1 (initial conv block)\n",
    "      x = ZeroPadding2D(padding=((3, 3), (3, 3)), name='conv1_pad')(inputs)\n",
    "      x = Conv2D(64, (7,7), use_bias=False, strides=(2,2),\n",
    "                    kernel_initializer=\"he_normal\", kernel_regularizer=l2(reg))(x)\n",
    "      x = BatchNormalization(axis=chanDim, name=\"bn_conv1\")(x)\n",
    "      x = Activation(\"relu\")(x)\n",
    "      x = ZeroPadding2D(padding=((1,1), (1,1)), name=\"pool1_pad\")(x)\n",
    "      x = MaxPooling2D(3, strides=2)(x)\n",
    "\n",
    "      for i in range(0, len(stages)):\n",
    "        stride = (1,1) if i == 0 else (2,2) # block 2 (projection block) w stride(1,1)\n",
    "\n",
    "        print(\"Stage {}, Stride={}\".format(i, stride))\n",
    "        x = SEResNet.residual_module(x, filters[i+1], stride,\n",
    "                                    chanDim=chanDim, red=True, bnEps=bnEps, bnMom=bnMom)\n",
    "        for j in range(0, stages[i] + 1): #stacking res block to each depth layer\n",
    "          x = SEResNet.residual_module(x, filters[i+1], stride=(1,1),\n",
    "                                      chanDim=chanDim, bnEps=bnEps,\n",
    "                                      bnMom=bnMom)\n",
    "      x = BatchNormalization(axis=chanDim, epsilon=bnEps,\n",
    "                                momentum=bnMom)(x)\n",
    "      x = Activation(\"relu\")(x)\n",
    "\n",
    "      if include_top:\n",
    "        x = GlobalAveragePooling2D()(x)\n",
    "        x = Dense(classes, use_bias=False, kernel_regularizer=l2(reg),\n",
    "                    activation='softmax')(x)\n",
    "      else:\n",
    "          if pooling == 'avg':\n",
    "              print(\"Adding average pool\")\n",
    "              x = GlobalAveragePooling2D()(x)\n",
    "          elif pooling == 'max':\n",
    "              x = GlobalMaxPooling2D()(x)\n",
    "\n",
    "      model = Model(inputs=inputs, outputs=x, name=\"SEResNet\")\n",
    "      return model\n",
    "\n",
    "def SEResNet18(input_shape,\n",
    "            classes=1000,\n",
    "            include_top=None,\n",
    "            input_tensor=None,\n",
    "            pooling=None):\n",
    "\n",
    "  (height, width, depth) = (input_shape[1], input_shape[2], input_shape[3])\n",
    "\n",
    "  return SEResNet.build(width=width, height=height, depth=depth, classes=classes, stages=(3, 3, 3, 3),\n",
    "                      include_top=include_top, pooling=pooling,\n",
    "                        filters=(64, 64, 128, 256, 512), reg=1e-5, bnEps=2e-5, bnMom=0.0)\n",
    "\n",
    "def SEResNet50(input_shape,\n",
    "            classes=1000,\n",
    "            include_top=None,\n",
    "            input_tensor=None,\n",
    "            pooling=None):\n",
    "\n",
    "  (height, width, depth) = (input_shape[1], input_shape[2], input_shape[3])\n",
    "\n",
    "  return SEResNet.build(width=width, height=height, depth=depth, classes=classes, stages=(3, 4, 6, 3),\n",
    "                      include_top=include_top, pooling=pooling,\n",
    "                        filters=(64, 256, 512, 1024, 2048), reg=1e-5, bnEps=2e-5, bnMom=0.0)\n",
    "\n",
    "def SEResNet101(input_shape,\n",
    "            classes=1000,\n",
    "            include_top=None,\n",
    "            input_tensor=None,\n",
    "            pooling=None):\n",
    "\n",
    "  (height, width, depth) = (input_shape[1], input_shape[2], input_shape[3])\n",
    "\n",
    "  return SEResNet.build(width=width, height=height, depth=depth,    classes=classes, stages=(3, 4, 23, 3),\n",
    "                      include_top=include_top, pooling=pooling,\n",
    "                        filters=(64, 256, 512, 1024, 2048), reg=1e-5, bnEps=2e-5, bnMom=0.0)\n",
    "\n",
    "\n",
    "def SEResNet152(input_shape,\n",
    "            classes=1000,\n",
    "            include_top=None,\n",
    "            input_tensor=None,\n",
    "            pooling=None):\n",
    "\n",
    "  (height, width, depth) = (input_shape[1], input_shape[2], input_shape[3])\n",
    "\n",
    "  return SEResNet.build(width=width, height=height, depth=depth, classes=classes,\n",
    "                          stages=[3, 8, 36, 3],\n",
    "                      include_top=include_top, pooling=pooling,\n",
    "                        filters=(64, 256, 512, 1024, 2048), reg=1e-5, bnEps=2e-5, bnMom=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "63d4d56a-fabb-4a27-9a35-92cc21052a2d",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3495058000.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[1], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    full code can be found here: https://github.com/evagian/Human-Protein-Atlas-Image-Classification-SENet/\u001b[0m\n\u001b[0m         ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    " ##full code can be found here: https://github.com/evagian/Human-Protein-Atlas-Image-Classification-SENet/\n",
    "\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import glob\n",
    "import pandas as pd\n",
    "import random\n",
    "import cv2\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "#create custom color maps\n",
    "cdict1 = {'red':   ((0.0,  0.0, 0.0),\n",
    "                   (1.0,  0.0, 0.0)),\n",
    "\n",
    "         'green': ((0.0,  0.0, 0.0),\n",
    "                   (0.75, 1.0, 1.0),\n",
    "                   (1.0,  1.0, 1.0)),\n",
    "\n",
    "         'blue':  ((0.0,  0.0, 0.0),\n",
    "                   (1.0,  0.0, 0.0))}\n",
    "\n",
    "plt.register_cmap(name='greens', data=cdict1)\n",
    "\n",
    "# number of images in batch\n",
    "batch_size = 8\n",
    "# models are saved here\n",
    "ckpt_dir = './checkpoint'\n",
    "# samples are saved here\n",
    "sample_dir = './sample'\n",
    "\n",
    "\n",
    "train_set = 'train'\n",
    "\n",
    "#import training data\n",
    "train_labels = pd.read_csv(\"../input/human-protein-atlas-image-classification-dataset/kaggle_protein_classes_augmented_one_hot.csv\")\n",
    "train_labels = train_labels.sort_values(by=['Id']).reset_index()\n",
    "print(train_labels.head())\n",
    "print(len(train_labels))\n",
    "\n",
    "seed = 100\n",
    "train_labels = shuffle(train_labels, random_state=seed).reset_index(drop=True)\n",
    "print(train_labels.head())\n",
    "print(len(train_labels))\n",
    "\n",
    "datay = train_labels.loc[101:200]\n",
    "\n",
    "datay = datay.iloc[:, 4:]\n",
    "# get image id\n",
    "data_im_id = train_labels.loc[101:200, \"Id\"]\n",
    "\n",
    "\n",
    "# read train data files\n",
    "data_files = []\n",
    "for im_id in data_im_id:\n",
    "    data_files.append(glob.glob('./input/train/{}_green.png'.format(im_id)))\n",
    "#data_files.sort()\n",
    "filepaths = [''.join(x) for x in data_files]\n",
    "\n",
    "print(\"testing code on few images... change lines 46 and 50 to include more training images\")\n",
    "print(\"number of training data x\", len(filepaths))\n",
    "\n",
    "# data augmentation options\n",
    "def data_augmentation(image, mode):\n",
    "    if mode == 0:\n",
    "        # original\n",
    "        return image\n",
    "    elif mode == 1:\n",
    "        # flip up and down\n",
    "        return np.flipud(image)\n",
    "    elif mode == 2:\n",
    "        # rotate 180 degree\n",
    "        return np.rot90(image, k=2)\n",
    "    elif mode == 3:\n",
    "        # flip left and right\n",
    "        return np.flipud(image)\n",
    "\n",
    "# data augmentation xDATA_AUG_TIMES times\n",
    "DATA_AUG_TIMES = 1\n",
    "count = 0\n",
    "\n",
    "# calculate the number of patches\n",
    "step = 0\n",
    "pat_size = 300\n",
    "stride = 300\n",
    "\n",
    "count = len(filepaths)\n",
    "\n",
    "origin_patch_num = count * DATA_AUG_TIMES\n",
    "print('origin_patch_num', origin_patch_num)\n",
    "numClasses = 28\n",
    "bat_size = 8\n",
    "# use power of 2 bat_size ex 128\n",
    "\n",
    "# calculate number of batches and patches\n",
    "# must be whole number\n",
    "if origin_patch_num % bat_size != 0:\n",
    "    numPatches = (divmod(origin_patch_num, bat_size)[0]+1) * bat_size\n",
    "\n",
    "else:\n",
    "    numPatches = origin_patch_num\n",
    "print(\"total patches =\", numPatches, \", batch size =\", bat_size,\n",
    "      \", total batches =\", numPatches / bat_size)\n",
    "\n",
    "# data matrix 4-D\n",
    "numPatches = int(numPatches)\n",
    "inputs = np.zeros((numPatches, pat_size, pat_size, 1), dtype=\"uint8\")\n",
    "inputsy = np.zeros((numPatches, numClasses), dtype=\"uint8\")\n",
    "\n",
    "count = 0\n",
    "\n",
    "# generate patches\n",
    "for i in range(len(filepaths)):\n",
    "    # get image id\n",
    "    im_id = data_im_id.iloc[i]\n",
    "\n",
    "    # open x\n",
    "    img_s = cv2.imread('../input/human-protein-atlas-image-classification/train/{}_green.png'.format(im_id), 0)\n",
    "\n",
    "\n",
    "    # open y\n",
    "    imgy =  datay.iloc[i]\n",
    "\n",
    "\n",
    "    img_sy = np.array(imgy, dtype=\"uint8\")\n",
    "\n",
    "    # data augmentation\n",
    "    for j in range(DATA_AUG_TIMES):\n",
    "        im_h, im_w= img_s.shape\n",
    "\n",
    "\n",
    "\n",
    "        z = random.randint(0, 212)\n",
    "        inputs[count, :, :, 0] = data_augmentation(\n",
    "            img_s[z:z + pat_size, z:z + pat_size], random.randint(0, 3))\n",
    "\n",
    "        inputsy[count, :] = img_sy\n",
    "\n",
    "        count += 1\n",
    "\n",
    "#imgplot = plt.imshow(inputs[count-9, :, :,0] )\n",
    "#plt.show()\n",
    "\n",
    "# pad training examples into the empty patches of the last batch\n",
    "if count < numPatches:\n",
    "    to_pad = numPatches - count\n",
    "    inputs[-to_pad:, :, :, :] = inputs[:to_pad, :, :, :]\n",
    "    inputsy[-to_pad:, :] = inputsy[:to_pad, :]\n",
    "\n",
    "\n",
    "\n",
    "#imgplot = plt.imshow(inputs[count-9, :, :,0] )\n",
    "#plt.show()\n",
    "\n",
    "\n",
    "# directory of patches\n",
    "save_dir='../Human Protein Atlas Image Classification Dataset/'\n",
    "\n",
    "\n",
    "# save x\n",
    "if not os.path.exists(save_dir):\n",
    "    os.mkdir(save_dir)\n",
    "np.save(os.path.join(save_dir,\n",
    "                     \"protein_image_patches_pat_size_300_bat_size_8_101_200\"),\n",
    "        inputs)\n",
    "print(\"size of x inputs tensor = \", str(inputs.shape))\n",
    "\n",
    "# save y\n",
    "\n",
    "np.save(os.path.join(save_dir,\n",
    "                     \"protein_image_classes_pat_size_300_bat_size_8_101_200\"),\n",
    "        inputsy)\n",
    "print(\"size of y inputs tensor = \", str(inputsy.shape))\n",
    "\n",
    "### up to here it generates patches\n",
    "\n",
    "\n",
    "# train the model (SENet architecture)\n",
    "\n",
    "import gc\n",
    "from sklearn.utils import shuffle\n",
    "from PIL import Image\n",
    "import time\n",
    "import random\n",
    "from glob import glob\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import sklearn\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from tflearn.layers.conv import global_avg_pool\n",
    "from tensorflow.contrib.layers import batch_norm, flatten\n",
    "from tensorflow.contrib.framework import arg_scope\n",
    "from keras.losses import binary_crossentropy, categorical_crossentropy\n",
    "import keras.backend as K\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.ops import array_ops\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '-1'\n",
    "\n",
    "\n",
    "\n",
    "class train_datatrain_da():\n",
    "    def __init__(self, filepath):\n",
    "        self.filepath = filepath\n",
    "        assert '.npy' in filepath\n",
    "        if not os.path.exists(filepath):\n",
    "            print(\"[!] Data file not exists\")\n",
    "            sys.exit(1)\n",
    "\n",
    "    def __enter__(self):\n",
    "        print(\"[*] Loading data...\")\n",
    "        self.data = np.load(self.filepath)\n",
    "\n",
    "        # np.random.shuffle(self.data)\n",
    "        print(\"[*] Load successfully...\")\n",
    "        return self.data\n",
    "\n",
    "    def __exit__(self, type, value, trace):\n",
    "        del self.data\n",
    "        gc.collect()\n",
    "        print(\"In __exit__()\")\n",
    "\n",
    "\n",
    "# data augmentation options# data a\n",
    "def data_augmentation(image, mode):\n",
    "    if mode == 0:\n",
    "        # original\n",
    "        return image\n",
    "    elif mode == 1:\n",
    "        # flip up and down\n",
    "        return np.flipud(image)\n",
    "    elif mode == 2:\n",
    "        # rotate 180 degree\n",
    "        return np.rot90(image, k=2)\n",
    "    elif mode == 3:\n",
    "        # flip left and right\n",
    "        return np.flipud(image)\n",
    "\n",
    "\n",
    "def f1(y_true, y_pred):\n",
    "    y_pred = K.round(y_pred)\n",
    "    tp = K.sum(K.cast(y_true * y_pred, 'float'), axis=0)\n",
    "    tn = K.sum(K.cast((1 - y_true) * (1 - y_pred), 'float'), axis=0)\n",
    "    fp = K.sum(K.cast((1 - y_true) * y_pred, 'float'), axis=0)\n",
    "    fn = K.sum(K.cast(y_true * (1 - y_pred), 'float'), axis=0)\n",
    "\n",
    "    p = tp / (tp + fp + K.epsilon())\n",
    "    r = tp / (tp + fn + K.epsilon())\n",
    "\n",
    "    f1 = 2 * p * r / (p + r + K.epsilon())\n",
    "    f1 = tf.where(tf.is_nan(f1), tf.zeros_like(f1), f1)\n",
    "    return K.mean(f1)\n",
    "\n",
    "\n",
    "def load_images(filelist):\n",
    "    # pixel value range 0-255\n",
    "    if not isinstance(filelist, list):\n",
    "        im = cv2.imread(filelist, 0)\n",
    "\n",
    "        #im = Image.open(filelist)#.convert('L')\n",
    "        return(im) #np.array(im).reshape(1, im.size[1], im.size[0], 1)\n",
    "    data = []\n",
    "    for file in filelist:\n",
    "\n",
    "        im = cv2.imread(file, 0)\n",
    "\n",
    "        #im = Image.open(file)#.convert('L')\n",
    "        data.append(im) #(np.array(im).reshape(1, im.size[1], im.size[0], 1))\n",
    "    return data\n",
    "\n",
    "\n",
    "def multi_label_hot(prediction, threshold=0.5):\n",
    "    prediction = tf.cast(prediction, tf.float32)\n",
    "    threshold = float(threshold)\n",
    "    return tf.cast(tf.greater(prediction, threshold), tf.float32)\n",
    "\n",
    "\n",
    "def focal_loss(prediction_tensor, target_tensor, weights=None, alpha=0.25, gamma=2):\n",
    "    \"\"\"Compute focal loss for predictions.\n",
    "        Multi-labels Focal loss formula:\n",
    "            FL = -alpha * (z-p)^gamma * log(p) -(1-alpha) * p^gamma * log(1-p)\n",
    "                 ,which alpha = 0.25, gamma = 2, p = sigmoid(x), z = target_tensor.\n",
    "    Args:\n",
    "     prediction_tensor: A float tensor of shape [batch_size, num_anchors,\n",
    "        num_classes] representing the predicted logits for each class\n",
    "     target_tensor: A float tensor of shape [batch_size, num_anchors,\n",
    "        num_classes] representing one-hot encoded classification targets\n",
    "     weights: A float tensor of shape [batch_size, num_anchors]\n",
    "     alpha: A scalar tensor for focal loss alpha hyper-parameter\n",
    "     gamma: A scalar tensor for focal loss gamma hyper-parameter\n",
    "    Returns:\n",
    "        loss: A (scalar) tensor representing the value of the loss function\n",
    "    \"\"\"\n",
    "    sigmoid_p = tf.nn.sigmoid(prediction_tensor)\n",
    "    zeros = array_ops.zeros_like(sigmoid_p, dtype=sigmoid_p.dtype)\n",
    "\n",
    "    # For poitive prediction, only need consider front part loss, back part is 0;\n",
    "    # target_tensor > zeros <=> z=1, so poitive coefficient = z - p.\n",
    "    pos_p_sub = array_ops.where(target_tensor > zeros, target_tensor - sigmoid_p, zeros)\n",
    "\n",
    "    # For negative prediction, only need consider back part loss, front part is 0;\n",
    "    # target_tensor > zeros <=> z=1, so negative coefficient = 0.\n",
    "    neg_p_sub = array_ops.where(target_tensor > zeros, zeros, sigmoid_p)\n",
    "    per_entry_cross_ent = - alpha * (pos_p_sub ** gamma) * tf.log(tf.clip_by_value(sigmoid_p, 1e-8, 1.0)) \\\n",
    "                          - (1 - alpha) * (neg_p_sub ** gamma) * tf.log(tf.clip_by_value(1.0 - sigmoid_p, 1e-8, 1.0))\n",
    "    return per_entry_cross_ent\n",
    "\n",
    "\n",
    "def f1_loss(y_true, y_pred):\n",
    "    tp = K.sum(y_true * y_pred, axis=0)\n",
    "    tn = K.sum((1 - y_true) * (1 - y_pred), axis=0)\n",
    "    fp = K.sum((1 - y_true) * y_pred, axis=0)\n",
    "    fn = K.sum(y_true * (1 - y_pred), axis=0)\n",
    "    p = tp / (tp + fp + K.epsilon())\n",
    "    r = tp / (tp + fn + K.epsilon())\n",
    "\n",
    "    f1 = 2 * p * r / (p + r + K.epsilon())\n",
    "    f1 = tf.where(tf.is_nan(f1), tf.zeros_like(f1), f1)\n",
    "    # 1 - K.mean(f1)\n",
    "    return 1 - f1\n",
    "\n",
    "\n",
    "momentum = 0.9\n",
    "cardinality = 2 #original  8 # how many split ?\n",
    "blocks = 2 # original 3 # 3 res_block ! (split + transition)\n",
    "depth = 64  # out channel\n",
    "\n",
    "reduction_ratio = 4\n",
    "batch_size = 8  # 128\n",
    "\n",
    "img_channels = 1\n",
    "class_num = 28\n",
    "weight_decay = 0.0005\n",
    "\n",
    "\n",
    "def conv_layer(input, filter, kernel, stride, padding='SAME', layer_name=\"conv\"):\n",
    "    with tf.name_scope(layer_name):\n",
    "        network = tf.layers.conv2d(inputs=input, use_bias=False, filters=filter, kernel_size=kernel, strides=stride,\n",
    "                                   padding=padding)\n",
    "        return network\n",
    "\n",
    "\n",
    "def Global_Average_Pooling(x):\n",
    "    return global_avg_pool(x, name='Global_avg_pooling')\n",
    "\n",
    "\n",
    "def Average_pooling(x, pool_size=[2, 2], stride=2, padding='SAME'):\n",
    "    return tf.layers.average_pooling2d(inputs=x, pool_size=pool_size, strides=stride, padding=padding)\n",
    "\n",
    "\n",
    "def Batch_Normalization(x, training, scope):\n",
    "    with arg_scope([batch_norm],\n",
    "                   scope=scope,\n",
    "                   updates_collections=None,\n",
    "                   decay=0.9,\n",
    "                   center=True,\n",
    "                   scale=True,\n",
    "                   zero_debias_moving_mean=True):\n",
    "        return tf.cond(training,\n",
    "                       lambda: batch_norm(inputs=x, is_training=training, reuse=None),\n",
    "                       lambda: batch_norm(inputs=x, is_training=training, reuse=True))\n",
    "\n",
    "\n",
    "def Relu(x):\n",
    "    return tf.nn.relu(x)\n",
    "\n",
    "\n",
    "def Sigmoid(x):\n",
    "    return tf.nn.sigmoid(x)\n",
    "\n",
    "\n",
    "def Concatenation(layers):\n",
    "    return tf.concat(layers, axis=3)\n",
    "\n",
    "\n",
    "def Fully_connected(x, units=class_num, layer_name='fully_connected'):\n",
    "    with tf.name_scope(layer_name):\n",
    "        return tf.layers.dense(inputs=x, use_bias=False, units=units)\n",
    "\n",
    "\n",
    "def first_layer(x, scope, training):\n",
    "    with tf.name_scope(scope):\n",
    "        x = conv_layer(x, filter=64, kernel=[3, 3], stride=1, layer_name=scope + '_conv1')\n",
    "        x = Batch_Normalization(x, training=training, scope=scope + '_batch1')\n",
    "        x = Relu(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "def transform_layer(x, stride, scope, training=True):\n",
    "    with tf.name_scope(scope):\n",
    "        x = conv_layer(x, filter=depth, kernel=[1, 1], stride=1, layer_name=scope + '_conv1')\n",
    "        x = Batch_Normalization(x, training=training, scope=scope + '_batch1')\n",
    "        x = Relu(x)\n",
    "\n",
    "        x = conv_layer(x, filter=depth, kernel=[3, 3], stride=stride, layer_name=scope + '_conv2')\n",
    "        x = Batch_Normalization(x, training=training, scope=scope + '_batch2')\n",
    "        x = Relu(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "def transition_layer(x, out_dim, scope, training=True):\n",
    "    with tf.name_scope(scope):\n",
    "        x = conv_layer(x, filter=out_dim, kernel=[1, 1], stride=1, layer_name=scope + '_conv1')\n",
    "        x = Batch_Normalization(x, training=training, scope=scope + '_batch1')\n",
    "        # x = Relu(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "def split_layer(input_x, stride, layer_name, training=True):\n",
    "    with tf.name_scope(layer_name):\n",
    "        layers_split = list()\n",
    "        for i in range(cardinality):\n",
    "            splits = transform_layer(input_x, stride=stride, scope=layer_name + '_splitN_' + str(i), training=training)\n",
    "            layers_split.append(splits)\n",
    "\n",
    "        return Concatenation(layers_split)\n",
    "\n",
    "\n",
    "def squeeze_excitation_layer(input_x, out_dim, ratio, layer_name):\n",
    "    with tf.name_scope(layer_name):\n",
    "        squeeze = Global_Average_Pooling(input_x)\n",
    "\n",
    "        excitation = Fully_connected(squeeze, units=out_dim / ratio, layer_name=layer_name + '_fully_connected1')\n",
    "        excitation = Relu(excitation)\n",
    "        excitation = Fully_connected(excitation, units=out_dim, layer_name=layer_name + '_fully_connected2')\n",
    "        excitation = Sigmoid(excitation)\n",
    "\n",
    "        excitation = tf.reshape(excitation, [-1, 1, 1, out_dim])\n",
    "        scale = input_x * excitation\n",
    "\n",
    "        return scale\n",
    "\n",
    "\n",
    "def residual_layer(input_x, out_dim, layer_num, res_block=blocks, training=True):\n",
    "    # split + transform(bottleneck) + transition + merge\n",
    "    # input_dim = input_x.get_shape().as_list()[-1]\n",
    "\n",
    "    for i in range(res_block):\n",
    "        input_dim = int(np.shape(input_x)[-1])\n",
    "\n",
    "        if input_dim * 2 == out_dim:\n",
    "            flag = True\n",
    "            stride = 2\n",
    "            channel = input_dim // 2\n",
    "        else:\n",
    "            flag = False\n",
    "            stride = 1\n",
    "\n",
    "        x = split_layer(input_x, stride=stride, layer_name='split_layer_'+layer_num+'_'+str(i), training = training )\n",
    "        x = transition_layer(x, out_dim=out_dim, scope='trans_layer_' + layer_num + '_' + str(i),\n",
    "                             training=training)\n",
    "        x = squeeze_excitation_layer(x, out_dim=out_dim, ratio=reduction_ratio,\n",
    "                                     layer_name='squeeze_layer_' + layer_num + '_' + str(i))\n",
    "\n",
    "        if flag is True:\n",
    "            pad_input_x = Average_pooling(input_x)\n",
    "            pad_input_x = tf.pad(pad_input_x,\n",
    "                                 [[0, 0], [0, 0], [0, 0], [channel, channel]])  # [?, height, width, channel]\n",
    "        else:\n",
    "            pad_input_x = input_x\n",
    "\n",
    "        input_x = Relu(x + pad_input_x)\n",
    "\n",
    "    return input_x\n",
    "\n",
    "\n",
    "# the model\n",
    "def SE_ResNeXt(input, is_training=True, output_channels=1):\n",
    "    training = is_training\n",
    "\n",
    "    input = first_layer(input, scope='first_layer', training=training)\n",
    "\n",
    "    x = residual_layer(input, out_dim=64, layer_num='1', training=training)  # out_dim=64\n",
    "    \n",
    "    # activate layer_num='2' and layer_num='3'\n",
    "    # x = residual_layer(x, out_dim=128, layer_num='2', training = training)\n",
    "    # x = residual_layer(x, out_dim=256, layer_num='3' , training = training)\n",
    "\n",
    "    x = Global_Average_Pooling(x)\n",
    "    x = flatten(x)\n",
    "\n",
    "    x = Fully_connected(x, layer_name='final_fully_connected')\n",
    "    return x\n",
    "\n",
    "\n",
    "def roc_auc_score(y_true, y_pred):\n",
    "    \"\"\" ROC AUC Score.\n",
    "    Approximates the Area Under Curve score, using approximation based on\n",
    "    the Wilcoxon-Mann-Whitney U statistic.\n",
    "    Yan, L., Dodier, R., Mozer, M. C., & Wolniewicz, R. (2003).\n",
    "    Optimizing Classifier Performance via an Approximation to the Wilcoxon-Mann-Whitney Statistic.\n",
    "    Measures overall performance for a full range of threshold levels.\n",
    "    Arguments:\n",
    "        y_pred: `Tensor`. Predicted values.\n",
    "        y_true: `Tensor` . Targets (labels), a probability distribution.\n",
    "    \"\"\"\n",
    "    with tf.name_scope(\"RocAucScore\"):\n",
    "        pos = tf.boolean_mask(y_pred, tf.cast(y_true, tf.bool))\n",
    "        neg = tf.boolean_mask(y_pred, ~tf.cast(y_true, tf.bool))\n",
    "        pos = tf.expand_dims(pos, 0)\n",
    "        neg = tf.expand_dims(neg, 1)\n",
    "        # original paper suggests performance is robust to exact parameter choice\n",
    "        gamma = 0.2\n",
    "        p = 3\n",
    "        difference = tf.zeros_like(pos * neg) + pos - neg - gamma\n",
    "        masked = tf.boolean_mask(difference, difference < 0.0)\n",
    "        return tf.reduce_sum(tf.pow(-masked, p))\n",
    "\n",
    "\n",
    "class denoiser(object):\n",
    "    def __init__(self, sess, input_c_dim=1, batch_size=8):\n",
    "        self.sess = sess\n",
    "        input_c_dim = input_c_dim\n",
    "\n",
    "        self.is_training = tf.placeholder(tf.bool, name='is_training')\n",
    "\n",
    "        # input images\n",
    "        #self.image_size = 512\n",
    "        self.img_channels = 1\n",
    "        self.weight_decay = 0.0005\n",
    "\n",
    "        self.class_num = 28\n",
    "        self.X = tf.placeholder(tf.float32, shape=[None, None, None , self.img_channels],\n",
    "                                name='input_image')\n",
    "\n",
    "        self.p = tf.placeholder(tf.float32, shape=[None, self.class_num], name='actual_classes')\n",
    "        # actual classes\n",
    "        self.one_hot_prediction = tf.placeholder(tf.float32, shape=[None, self.class_num], name='one_hot_prediction')\n",
    "\n",
    "        # predicted classes\n",
    "        self.logit_q = tf.placeholder(tf.float32, shape=[None, self.class_num], name='input_classes_logit')\n",
    "        # self.q = tf.placeholder(tf.float32, shape=[None, self.class_num],  name='input_classes')\n",
    "\n",
    "        # predicted probabilities\n",
    "        self.logit_q = SE_ResNeXt(self.X, is_training=self.is_training)\n",
    "\n",
    "        # learning rate\n",
    "        self.lr = tf.placeholder(tf.float32, name='learning_rate')\n",
    "\n",
    "        # prediction after softmax\n",
    "        self.one_hot_prediction = multi_label_hot(self.logit_q)\n",
    "        self.loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(labels=self.p, logits=self.logit_q))\n",
    "\n",
    "\n",
    "\n",
    "        # f1_score\n",
    "\n",
    "        # self.eva_f1_score = sklearn.metrics.f1_score(self.p, self.q, labels=None, pos_label=1, average='micro') # or average='weighted' and 'samples'\n",
    "\n",
    "        self.eva_f1_score = f1(self.p, self.one_hot_prediction)\n",
    "        # adam optimizer\n",
    "        # default variables\n",
    "        # beta one 0.9\n",
    "        # beta two 0.999\n",
    "        # Epsilon 10^-8\n",
    "        # beta1=0.9, beta2=0.999, epsilon=1e-08\n",
    "        optimizer = tf.train.AdamOptimizer(learning_rate=self.lr,\n",
    "                                           name='AdamOptimizer')\n",
    "\n",
    "        # returns the list of values in the collection with the given name\n",
    "        # UPDATE_OPS is a collection of ops (operations performed when the\n",
    "        # graph runs, like multiplication, ReLU, etc.), not variables.\n",
    "        # Specifically, this collection maintains a list of ops which\n",
    "        # need to run after every training step.\n",
    "        update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "        with tf.control_dependencies(update_ops):\n",
    "            # min loss\n",
    "            self.train_op = optimizer.minimize(self.loss)\n",
    "        # initialize variables\n",
    "        init = tf.global_variables_initializer()\n",
    "        self.sess.run(init)\n",
    "        print(\"[*] Initialize model successfully...\")\n",
    "\n",
    "    def evaluate(self, iter_num, eval_files, eval_datay, sample_dir,\n",
    "                 summary_merged, summary_writer):\n",
    "        # assert test_data value range is 0-255\n",
    "        outstreval = \"[*] Evaluating...\\n\"\n",
    "\n",
    "        print(\"[*] Evaluating...\")\n",
    "        f1_score_sum = 0\n",
    "\n",
    "        input_image = np.zeros((1, 512, 512, 1), dtype=\"uint8\")\n",
    "\n",
    "        for idx in range(len(eval_files)):\n",
    "\n",
    "            in_image = cv2.imread(eval_files[idx], 0)\n",
    "\n",
    "\n",
    "            input_image[0,:,:,0] = in_image\n",
    "\n",
    "\n",
    "            actual_classes = eval_datay.iloc[[idx]].values.reshape((1, 28))\n",
    "\n",
    "\n",
    "\n",
    "            output_classes, input_image, one_hot_prediction, f1_score_summary = self.sess.run(\n",
    "                [self.logit_q, self.X, self.one_hot_prediction, summary_merged],\n",
    "\n",
    "                feed_dict={self.p: actual_classes, self.X: input_image,\n",
    "                           self.is_training: False})\n",
    "\n",
    "            summary_writer.add_summary(f1_score_summary, iter_num)\n",
    "            # feed_dict={self.Y_: actual_classes,\n",
    "            # self.is_training: False})\n",
    "\n",
    "            # np.clip\n",
    "            # Given an interval, values outside the interval are clipped to\n",
    "            # the interval edges.\n",
    "            # For example, if an interval of [0, 1] is specified,\n",
    "            # values smaller than 0 become 0, and values larger than 1 become 1.\n",
    "\n",
    "            one_hot_prediction = one_hot_prediction.astype('uint8')\n",
    "\n",
    "            groundtruth_classes = actual_classes.astype('uint8')\n",
    "\n",
    "            # calculate f1_score\n",
    "            groundtruth_classes = np.ndarray.transpose(groundtruth_classes)\n",
    "            one_hot_prediction = np.ndarray.transpose(one_hot_prediction)\n",
    "\n",
    "            f1_score = sklearn.metrics.f1_score(groundtruth_classes, one_hot_prediction, labels=None, average='macro')\n",
    "\n",
    "            print('img ', str(idx + 1), ' f1_score:', str(f1_score))\n",
    "\n",
    "            outstreval = outstreval + ' img ' + str(idx + 1) + ' f1_score: ' + str(\n",
    "                f1_score) + '\\n'\n",
    "\n",
    "            f1_score_sum += f1_score\n",
    "\n",
    "\n",
    "        #print('evaluate CNN')\n",
    "        #imgplot = plt.imshow(input_image[0,:,:,0])\n",
    "        #plt.show()\n",
    "\n",
    "        avg_f1_score = f1_score_sum / len(eval_files)\n",
    "\n",
    "        print('--- Test ---- Average f1_score %.2f ---- ' % (avg_f1_score))\n",
    "\n",
    "        # add average f1_score to tensorboard\n",
    "\n",
    "        outstreval = outstreval + '--- Test ---- Average f1_score ' + str(\n",
    "            avg_f1_score) + ' ---\\n'\n",
    "\n",
    "        filename = 'outstreval' + str(iter_num) + '.txt'\n",
    "        file = open(filename, 'w')\n",
    "        file.write(outstreval)\n",
    "        file.close()\n",
    "\n",
    "    def train(self, data, datay, eval_files, eval_datay, batch_size, ckpt_dir,\n",
    "              epoch, lr, sample_dir, eval_every_epoch=1):\n",
    "\n",
    "\n",
    "        # assert data range is between 0 and 1\n",
    "        numBatch = int((len(data) + 1) / batch_size)\n",
    "\n",
    "\n",
    "        print('numBatch', (len(data)) / batch_size, len(data), batch_size)\n",
    "\n",
    "        # if pretrained model exists - load pretrained model\n",
    "        # else train new model\n",
    "        # ckpt_dir=checkpoint\n",
    "        load_model_status, global_step = self.load(ckpt_dir)\n",
    "        if load_model_status:\n",
    "            iter_num = global_step\n",
    "            start_epoch = global_step // numBatch\n",
    "            start_step = global_step % numBatch\n",
    "\n",
    "\n",
    "            print(\"[*] Model restore success!\")\n",
    "        else:\n",
    "            iter_num = 0\n",
    "            start_epoch = 0\n",
    "            start_step = 0\n",
    "            print(\"[*] Did not find pretrained model!\")\n",
    "        # make summary\n",
    "        tf.summary.scalar('loss', self.loss)\n",
    "        tf.summary.scalar('lr', self.lr)\n",
    "        writer = tf.summary.FileWriter('./logs', self.sess.graph)\n",
    "        merged = tf.summary.merge_all()\n",
    "        summary_f1_score = tf.summary.scalar('eva_f1_score', self.eva_f1_score)\n",
    "\n",
    "        outstrtr = \"Save output here.\\n\"\n",
    "\n",
    "        outstrtr = outstrtr + \"[*] Start training, with start epoch \" + str(start_epoch) + \" start iter \" + str(\n",
    "            iter_num) + \"\\n\"\n",
    "\n",
    "        print(\"[*] Start training, with start epoch %d start iter %d : \" % (\n",
    "            start_epoch, iter_num))\n",
    "        print('[*][*][*] Go to line 328 and 329 and set cardinality and blocks to their original values')\n",
    "        print('[*][*][*] Uncomment lines 482 and 483')\n",
    "\n",
    "        start_time = time.time()\n",
    "\n",
    "\n",
    "        self.evaluate(iter_num,  eval_files, eval_datay, sample_dir=sample_dir,\n",
    "                      summary_merged=summary_f1_score,\n",
    "                      summary_writer=writer)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        for epoch in range(start_epoch, epoch):\n",
    "\n",
    "\n",
    "            for batch_id in range(start_step, numBatch):\n",
    "\n",
    "                batch_images = data[batch_id * batch_size:(\n",
    "                                                                  batch_id + 1) * batch_size,\n",
    "                               :, :, :]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                batch_images = batch_images.astype(\n",
    "                    np.int8)\n",
    "\n",
    "\n",
    "                batch_imagesy = datay[batch_id * batch_size:(\n",
    "                                                                    batch_id + 1) * batch_size,\n",
    "                                :]\n",
    "                batch_imagesy = batch_imagesy.astype(\n",
    "                    np.int8)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                _, loss, summary = self.sess.run(\n",
    "                    [self.train_op, self.loss, merged],\n",
    "                    feed_dict={self.p: batch_imagesy, self.X: batch_images,\n",
    "                               self.lr: lr[epoch],\n",
    "                               self.is_training: True})\n",
    "\n",
    "                # add f1_score as well\n",
    "                outstrtr = outstrtr + \"Epoch: \" + str(epoch + 1) + \" [\" + str(\n",
    "                    batch_id + 1) + \"/\" + str(numBatch) + \"] \" + \"time: \" + str(\n",
    "                    time.time() - start_time) + \"loss: \" + str(loss) + \"\\n\"\n",
    "\n",
    "                print(\"Epoch: [%2d] [%4d/%4d] time: %4.4f, loss: %.6f\"\n",
    "\n",
    "                      % (epoch + 1, batch_id + 1, numBatch,\n",
    "                         time.time() - start_time, loss))\n",
    "\n",
    "                iter_num += 1\n",
    "                writer.add_summary(summary, iter_num)\n",
    "            if np.mod(epoch + 1, eval_every_epoch) == 0:\n",
    "                self.evaluate(iter_num, eval_files, eval_datay,\n",
    "                              sample_dir=sample_dir,\n",
    "                              summary_merged=summary_f1_score,\n",
    "                              summary_writer=writer)  # eval_data value range is 0-255\n",
    "                self.save(iter_num, ckpt_dir)\n",
    "\n",
    "\n",
    "\n",
    "        print(\"[*] Finish training.\")\n",
    "        filename = 'outstrtr' + str(epoch + 1) + '.txt'\n",
    "        file = open(filename, 'w')\n",
    "        file.write(outstrtr)\n",
    "        file.close()\n",
    "\n",
    "    def save(self, iter_num, ckpt_dir, model_name='CNN-tensorflow'):\n",
    "        saver = tf.train.Saver()\n",
    "        checkpoint_dir = ckpt_dir\n",
    "        if not os.path.exists(checkpoint_dir):\n",
    "            os.makedirs(checkpoint_dir)\n",
    "        print(\"[*] Saving model...\")\n",
    "        saver.save(self.sess,\n",
    "                   os.path.join(checkpoint_dir, model_name),\n",
    "                   global_step=iter_num)\n",
    "\n",
    "    def load(self, checkpoint_dir):\n",
    "\n",
    "        print(\"[*] Reading checkpoint...\")\n",
    "        saver = tf.train.Saver()\n",
    "        ckpt = tf.train.get_checkpoint_state(checkpoint_dir)\n",
    "        if ckpt and ckpt.model_checkpoint_path:\n",
    "            full_path = tf.train.latest_checkpoint(checkpoint_dir)\n",
    "            global_step = int(full_path.split('/')[-1].split('-')[-1])\n",
    "            saver.restore(self.sess, full_path)\n",
    "            return True, global_step\n",
    "        else:\n",
    "            return False, 0\n",
    "\n",
    "\n",
    "    def test(self,test_files,  test_datay, ckpt_dir, save_dir):\n",
    "\n",
    "        \"\"\"Test CNN\"\"\"\n",
    "        # init variables\n",
    "        tf.initialize_all_variables().run()\n",
    "        assert len(test_files) != 0, 'No testing data x!'\n",
    "        assert len(test_datay) != 0, 'No testing data y!'\n",
    "\n",
    "        load_model_status, global_step = self.load(ckpt_dir)\n",
    "        assert load_model_status == True, '[!] Load weights FAILED...'\n",
    "        print(\" [*] Load weights SUCCESS...\")\n",
    "        f1_score_sum = 0\n",
    "        print(\"[*] \" + \" start testing...\")\n",
    "\n",
    "        input_image = np.zeros((1, 512, 512, 1), dtype=\"uint8\")\n",
    "\n",
    "\n",
    "        for idx in range(len(test_files)):\n",
    "\n",
    "            # open x\n",
    "            in_image = cv2.imread(test_files[idx], 0)\n",
    "\n",
    "            input_image[0,:,:,0] = in_image\n",
    "\n",
    "\n",
    "            actual_classes = test_datay.iloc[[idx]].values.reshape((1, 28))\n",
    "\n",
    "\n",
    "            output_classes, one_hot_prediction = self.sess.run([self.logit_q, self.one_hot_prediction],\n",
    "                                                               feed_dict={\n",
    "                                                                   self.p: actual_classes,\n",
    "                                                                   self.X: input_image,\n",
    "                                                                   self.is_training: False})\n",
    "\n",
    "            groundtruth_classes = actual_classes.astype('uint8')\n",
    "            one_hot_prediction = one_hot_prediction.astype('uint8')\n",
    "\n",
    "\n",
    "            # calculate f1_score\n",
    "            groundtruth_classes = np.ndarray.transpose(groundtruth_classes)\n",
    "            one_hot_prediction = np.ndarray.transpose(one_hot_prediction)\n",
    "\n",
    "            print( groundtruth_classes, one_hot_prediction)\n",
    "            f1_score = sklearn.metrics.f1_score(groundtruth_classes, one_hot_prediction, labels=None, average='macro')\n",
    "            print(np.argwhere(output_classes))\n",
    "            print(\"img%d f1_score: %.2f\" % (idx, f1_score))\n",
    "            f1_score_sum += f1_score\n",
    "        #print('test CNN')\n",
    "        #imgplot = plt.imshow(input_image[0,:,:,0])\n",
    "        #plt.show()\n",
    "\n",
    "        avg_f1_score = f1_score_sum / len(test_files)\n",
    "\n",
    "        print(\"--- Average f1_score %.2f ---\" % avg_f1_score)\n",
    "\n",
    "\n",
    "def make_image_row(image):\n",
    "    image = np.reshape(np.array(image, dtype=\"uint8\"),\n",
    "                       (image.size[0], image.size[1], 1))\n",
    "\n",
    "    return image\n",
    "\n",
    "\n",
    "class train_data():\n",
    "    def __init__(self, filepath):\n",
    "        self.filepath = filepath\n",
    "        assert '.npy' in filepath\n",
    "        if not os.path.exists(filepath):\n",
    "            print(\"[!] Data file not exists\")\n",
    "            sys.exit(1)\n",
    "\n",
    "    def __enter__(self):\n",
    "        print(\"[*] Loading data...\")\n",
    "        self.data = np.load(self.filepath)\n",
    "\n",
    "        # np.random.shuffle(self.data)\n",
    "        print(\"[*] Load successfully...\")\n",
    "        return self.data\n",
    "\n",
    "    def __exit__(self, type, value, trace):\n",
    "        del self.data\n",
    "        gc.collect()\n",
    "        print(\"In __exit__()\")\n",
    "\n",
    "\n",
    "def load_data(filepath):\n",
    "    return train_data(filepath=filepath)\n",
    "\n",
    "\n",
    "# denoiser_train\n",
    "def denoiser_train(denoiser, lr):\n",
    "\n",
    "\n",
    "    with load_data(filepath='../Human Protein Atlas Image Classification Dataset/protein_image_patches_pat_size_300_bat_size_8_101_200.npy') as data:\n",
    "        with load_data(filepath='../Human Protein Atlas Image Classification Dataset/protein_image_classes_pat_size_300_bat_size_8_101_200.npy') as datay:\n",
    "\n",
    "\n",
    "            train_labels = pd.read_csv(\n",
    "                '../input/human-protein-atlas-image-classification-dataset/kaggle_protein_classes_augmented_one_hot.csv')\n",
    "            train_labels = train_labels.sort_values(by=['Id']).reset_index()\n",
    "            seed = 100\n",
    "            train_labels = shuffle(train_labels, random_state=seed).reset_index(drop=True)\n",
    "\n",
    "\n",
    "\n",
    "            eval_datay = train_labels.loc[:10]\n",
    "\n",
    "            eval_datay = eval_datay.iloc[:, 4:]\n",
    "\n",
    "            # print(train_labels.head())\n",
    "\n",
    "            # get image id\n",
    "            eval_data_im_id = train_labels.loc[:10, \"Id\"]\n",
    "\n",
    "            # get each image channel as a greyscale image (second argument 0 in imread)\n",
    "\n",
    "            eval_files = []\n",
    "            for eval_im_id in eval_data_im_id:\n",
    "                eval_files.append(\n",
    "                    glob('../input/human-protein-atlas-image-classification/train/{}_green.png'.format(eval_im_id)))\n",
    "            eval_files = [''.join(x) for x in eval_files]\n",
    "\n",
    "\n",
    "            # if there is a small memory, please comment this line and uncomment the line99 in model.py\n",
    "            #data = data.astype(np.int8) / 255.0  # normalize the data to 0-1\n",
    "\n",
    "\n",
    "            # number of images in batch\n",
    "            batch_size = 8\n",
    "            # models are saved here\n",
    "            ckpt_dir = './checkpoint'\n",
    "            epoch = 2\n",
    "            # samples are saved here\n",
    "            sample_dir = './sample'\n",
    "\n",
    "            lr = 0.1\n",
    "            lr = lr * np.ones([epoch])\n",
    "\n",
    "            lr[30:] = lr[0] / 10.0\n",
    "            lr[60:] = lr[0] / 100.0\n",
    "            lr[90:] = lr[0] / 1000.0\n",
    "\n",
    "            train_set = 'train'\n",
    "\n",
    "\n",
    "            #eval_data = load_images(eval_files)  # list of array of different size, 4-D, pixel value range is 0-255\n",
    "\n",
    "            denoiser.train(data, datay, eval_files, eval_datay,\n",
    "                           batch_size=batch_size, ckpt_dir=ckpt_dir,\n",
    "                           epoch=epoch, lr=lr,\n",
    "                           sample_dir=sample_dir)\n",
    "\n",
    "\n",
    "\n",
    "# denoiser_test\n",
    "# dataset for testing\n",
    "\n",
    "# this is ok\n",
    "def denoiser_test(denoiser):\n",
    "    # models are saved here\n",
    "    ckpt_dir = './checkpoint'\n",
    "    # test sample are saved here\n",
    "    test_dir = './test'\n",
    "\n",
    "    test_set = 'test_set'\n",
    "\n",
    "    # load test images\n",
    "    train_set = 'train'\n",
    "\n",
    "    train_labels = pd.read_csv('../input/human-protein-atlas-image-classification-dataset/kaggle_protein_classes_augmented_one_hot.csv')\n",
    "\n",
    "    train_labels = train_labels.sort_values(by=['Id']).reset_index()\n",
    "    seed = 100\n",
    "    train_labels = shuffle(train_labels, random_state=seed).reset_index(drop=True)\n",
    "\n",
    "    test_filesy = train_labels.loc[11:20]\n",
    "    test_datay = test_filesy.iloc[:, 4:]\n",
    "\n",
    "    #test_datay = test_filesy\n",
    "\n",
    "    # get image id\n",
    "    test_data_im_id = train_labels.loc[11:20, \"Id\"]\n",
    "\n",
    "    # get each image channel as a greyscale image (second argument 0 in imread)\n",
    "\n",
    "    test_files = []\n",
    "    for eval_im_id in test_data_im_id:\n",
    "        test_files.append(glob('../input/human-protein-atlas-image-classification/train/{}_green.png'.format(eval_im_id)))\n",
    "    # data_files.sort()\n",
    "    test_files = [''.join(x) for x in test_files]\n",
    "\n",
    "    denoiser.test(test_files,  test_datay, ckpt_dir=ckpt_dir, save_dir=test_dir)\n",
    "\n",
    "\n",
    "######## Start training here\n",
    "\n",
    "# initial learning rate for adam\n",
    "lr = 0.1\n",
    "\n",
    "# number of epochs\n",
    "\n",
    "epoch = 2\n",
    "# use_gpu=0: use tensorflow cpu\n",
    "# use_gpu=1: use tensorflow gpu\n",
    "use_gpu = 0\n",
    "\n",
    "# train or test\n",
    "phase = 'train'\n",
    "ckpt_dir = './checkpoint'\n",
    "sample_dir = './sample'\n",
    "test_dir = './test'\n",
    "\n",
    "if not os.path.exists(ckpt_dir):\n",
    "    os.makedirs(ckpt_dir)\n",
    "if not os.path.exists(sample_dir):\n",
    "    os.makedirs(sample_dir)\n",
    "if not os.path.exists(test_dir):\n",
    "    os.makedirs(test_dir)\n",
    "\n",
    "lr = lr * np.ones([epoch])\n",
    "\n",
    "lr[30:] = lr[0] / 10.0\n",
    "lr[60:] = lr[0] / 100.0\n",
    "lr[90:] = lr[0] / 1000.0\n",
    "\n",
    "tf.reset_default_graph()\n",
    "if use_gpu:\n",
    "    # added to control the gpu memory\n",
    "    print(\"GPU\\n\")\n",
    "    gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=0.9)\n",
    "    with tf.Session(config=tf.ConfigProto(gpu_options=gpu_options)) as sess:\n",
    "        model = denoiser(sess)\n",
    "        if phase == 'train':\n",
    "            denoiser_train(model, lr=lr)\n",
    "        elif phase == 'test':\n",
    "            denoiser_test(model)\n",
    "        else:\n",
    "            print('[!]Unknown phase')\n",
    "            exit(0)\n",
    "else:\n",
    "    print(\"CPU\\n\")\n",
    "    with tf.Session() as sess:\n",
    "        model = denoiser(sess)\n",
    "        if phase == 'train':\n",
    "            denoiser_train(model, lr=lr)\n",
    "        elif phase == 'test':\n",
    "            denoiser_test(model)\n",
    "        else:\n",
    "            print('[!]Unknown phase')\n",
    "            exit(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80721f41-c1d2-4b5f-8fe4-902237d5b9b9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
